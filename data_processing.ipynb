{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the japanese phone dictionary \n",
    "def load_phone_dict(path):\n",
    "  phone_dict = list()\n",
    "  with open(path, 'r') as f:\n",
    "    for line in f:\n",
    "      phone_dict.append(line.strip())\n",
    "  return phone_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phone_to_one_hot(phone, phone_dict):\n",
    "  tmp = list(np.zeros(len(phone_dict)))\n",
    "  if phone=='None':   \n",
    "    return tmp\n",
    "  else:\n",
    "    tmp[phone_dict.index(phone)] = 1.0\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_frame(time, window_size, step_size):\n",
    "  number_windows=(time-2*window_size)//step_size\n",
    "  if number_windows >= 0:\n",
    "    return number_windows\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### convert /mono/.labs to csv\n",
    "#### a floder under /mono/ called /csv/ will be created and it will hold all the csv files with current, next, before\n",
    "#### the format of one example will be shown below\n",
    "\n",
    "label_path = '/Users/ShiyuMu/Desktop/HTS-demo_NIT-SONG070-F001/data/labels/mono/'\n",
    "fileList = [label_path + f for f in os.listdir(label_path) if f.endswith('.lab')]\n",
    "try:\n",
    "  # create dictionary to hold all the csv file \n",
    "  os.mkdir(label_path + 'csv/');\n",
    "  print('csv dictionary created')\n",
    "except:\n",
    "  pass\n",
    "for file in fileList:\n",
    "  df = pd.read_csv(file, sep=\" \", header=None)\n",
    "  df.columns = [\"beg\", \"end\", \"current\"]\n",
    "  df['before'] = pd.Series(['None']).append(df['current']).reset_index(drop=True)\n",
    "  df['next'] = df['current'][1:].append(pd.Series(['None'])).reset_index(drop=True)\n",
    "  df.to_csv(label_path + 'csv/'+ file.split('/')[-1]+'.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example of loading csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the path we just created\n",
    "csv_path = label_path + 'csv/'\n",
    "# get all csv files \n",
    "csvList = [csv_path + f for f in os.listdir(csv_path) if f.endswith('.csv')]\n",
    "df_list = list()\n",
    "## add all csv files as dataframe to a list\n",
    "for file in csvList:\n",
    "  df = pd.read_csv(file, sep='\\t')\n",
    "  df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>current</th>\n",
       "      <th>before</th>\n",
       "      <th>next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23800000</td>\n",
       "      <td>pau</td>\n",
       "      <td>None</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23800000</td>\n",
       "      <td>24400000</td>\n",
       "      <td>n</td>\n",
       "      <td>pau</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24400000</td>\n",
       "      <td>30450000</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30450000</td>\n",
       "      <td>35800000</td>\n",
       "      <td>N</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35800000</td>\n",
       "      <td>36200000</td>\n",
       "      <td>n</td>\n",
       "      <td>N</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        beg       end current before next\n",
       "0         0  23800000     pau   None    n\n",
       "1  23800000  24400000       n    pau    e\n",
       "2  24400000  30450000       e      n    N\n",
       "3  30450000  35800000       N      e    n\n",
       "4  35800000  36200000       n      N    e"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## the df_list contains 31 dataframe (since we have 31 dataset)\n",
    "## one dataframe will look like this. beg and end here indicates nonoseconds\n",
    "df_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file in csvList:\n",
    "#   print(file.split('/')[-1].split('.csv')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load phoneme dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_dict_path = 'JPN_phone_dict.txt'\n",
    "phone_dict = load_phone_dict(phone_dict_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert timestamps to frame numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### define window size and step size to convert timestamp to frame id\n",
    "window_size = 250000\n",
    "step_size = 100000\n",
    "\n",
    "for df in df_list:\n",
    "#   print(len(df['beg'].values))\n",
    "  for index in range(len(df['beg'].values)):\n",
    "#     print(index)\n",
    "    df['beg'].values[index] = time_to_frame(df['beg'].values[index], window_size, step_size)\n",
    "  for index in range(len(df['end'].values)):\n",
    "#     print(index)\n",
    "    df['end'].values[index] = time_to_frame(df['end'].values[index], window_size, step_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>current</th>\n",
       "      <th>before</th>\n",
       "      <th>next</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>pau</td>\n",
       "      <td>None</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233</td>\n",
       "      <td>239</td>\n",
       "      <td>n</td>\n",
       "      <td>pau</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>239</td>\n",
       "      <td>299</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299</td>\n",
       "      <td>353</td>\n",
       "      <td>N</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>353</td>\n",
       "      <td>357</td>\n",
       "      <td>n</td>\n",
       "      <td>N</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beg  end current before next\n",
       "0    0  233     pau   None    n\n",
       "1  233  239       n    pau    e\n",
       "2  239  299       e      n    N\n",
       "3  299  353       N      e    n\n",
       "4  353  357       n      N    e"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now df_list contains 31 dataframe, one would be like this\n",
    "df_list[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfold all frames and list them one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolded_df_list = list()\n",
    "for dataset in df_list:\n",
    "  unfold_list = list()\n",
    "  for index in range(dataset.shape[0]):\n",
    "    beg_ = dataset.iloc[index]['beg']\n",
    "    end_ = dataset.iloc[index]['end']\n",
    "    current_ = np.asarray(phone_to_one_hot(dataset.iloc[index]['current'], phone_dict))\n",
    "    before_ = np.asarray(phone_to_one_hot(dataset.iloc[index]['before'], phone_dict))\n",
    "    next_ = np.asarray(phone_to_one_hot(dataset.iloc[index]['next'], phone_dict))\n",
    "    corase_encoding_vectors = np.asarray(corase_encoding(index, beg_, end_))\n",
    "#     print(corase_encoding_vectors)\n",
    "    if index == 0:\n",
    "      unfold_list.append([beg_, end_, np.asarray(phone_to_one_hot('None', phone_dict)), current_, next_, corase_encoding(beg_, beg_, end_)])\n",
    "    else:\n",
    "      unfold_list.append([beg_, end_, before_, current_, next_, corase_encoding(beg_, beg_, end_)])\n",
    "    for i in range(beg_+1, end_):\n",
    "      unfold_list.append([beg_, end_, before_, current_, next_, corase_encoding(i, beg_, end_)])\n",
    "    if index == (dataset.shape[0] -1):\n",
    "      unfold_list.append([beg_, end_, before_, current_, np.asarray(phone_to_one_hot('None', phone_dict)), corase_encoding(end_, beg_, end_)])\n",
    "    else:\n",
    "      unfold_list.append([beg_, end_, before_, current_, next_, corase_encoding(end_, beg_, end_)])\n",
    "  unfold_df = pd.DataFrame(unfold_list, columns=['beg', 'end', 'before', 'current', 'next', 'coarse'])\n",
    "  unfolded_df_list.append(unfold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corase_encoding(current_index, beg, end):\n",
    "  middle = int((end-beg)/2)\n",
    "  if current_index == beg:\n",
    "    return [1, 0, 0]\n",
    "  elif current_index == middle:\n",
    "    return [0, 1, 0]\n",
    "  elif current_index == end:\n",
    "    return [0, 0, 1]\n",
    "  else:\n",
    "    inverse_dist_beg = 1/np.abs(current_index-beg)\n",
    "    inverse_dist_middle = 1/np.abs(current_index-middle)\n",
    "    inverse_dist_end = 1/np.abs(current_index-end)\n",
    "    p_beg = inverse_dist_beg/(inverse_dist_beg+inverse_dist_middle+inverse_dist_end)\n",
    "    p_middle = inverse_dist_middle/(inverse_dist_beg+inverse_dist_middle+inverse_dist_end)\n",
    "    p_end = inverse_dist_end/(inverse_dist_beg+inverse_dist_middle+inverse_dist_end)\n",
    "    return [p_beg, p_middle, p_end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04943729903536978, 0.9063504823151126, 0.044212218649517694]\n"
     ]
    }
   ],
   "source": [
    "## see how corase_encoding works. \n",
    "## Input: current position, beg of this phoneme, end of this phoneme \n",
    "## Output: the probability of the current frame's position in the [begining, middle, end] of the current phoneme\n",
    "print(corase_encoding(110, 0, 233))\n",
    "## This function has been built in the feature generation process itself so you don't need to worry about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>before</th>\n",
       "      <th>current</th>\n",
       "      <th>next</th>\n",
       "      <th>coarse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.9871609871609871, 0.008584008584008583, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.9744671403197158, 0.017095914742451153, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.961915688959621, 0.025537584662644806, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.949503924181845, 0.03391085443506589, 0.016...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beg  end                                             before  \\\n",
       "0    0  233  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1    0  233  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2    0  233  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3    0  233  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4    0  233  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                             current  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                next  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                              coarse  \n",
       "0                                          [1, 0, 0]  \n",
       "1  [0.9871609871609871, 0.008584008584008583, 0.0...  \n",
       "2  [0.9744671403197158, 0.017095914742451153, 0.0...  \n",
       "3  [0.961915688959621, 0.025537584662644806, 0.01...  \n",
       "4  [0.949503924181845, 0.03391085443506589, 0.016...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now unfolded_df_list is a list contains 31 dataframe, \n",
    "## one example would be like this, the index at the front means frame id\n",
    "unfolded_df_list[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_folder(folder_name):\n",
    "  try:  \n",
    "    os.mkdir(folder_name);\n",
    "#     print('folder created: ', folder_name)\n",
    "  except:\n",
    "#     print('folder already exist: ', folder_name)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Save npy files as required\n",
    "creat_folder('npy')  \n",
    "for i in range(len(csvList)):\n",
    "  lab_name = csvList[i].split('/')[-1].split('.csv')[0]\n",
    "  creat_folder('./npy/'+lab_name)\n",
    "#   creat_folder('./npy/'+lab_name+'/current')\n",
    "#   creat_folder('./npy/'+lab_name+'/next')\n",
    "#   creat_folder('./npy/'+lab_name+'/before')\n",
    "#   creat_folder('./npy/'+lab_name+'/corase_encoding')\n",
    "  np.save('./npy/'+lab_name+'/current.npy', unfolded_df_list[i]['current'])\n",
    "  np.save('./npy/'+lab_name+'/next.npy', unfolded_df_list[i]['next'])\n",
    "  np.save('./npy/'+lab_name+'/before.npy', unfolded_df_list[i]['before'])\n",
    "  np.save('./npy/'+lab_name+'/corase_encoding.npy', unfolded_df_list[i]['coarse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "       array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "       array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "       ...,\n",
       "       array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "       array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "       array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Example of loading a noy file\n",
    "np_array_example = np.load('./npy/nitech_jp_song070_f001_010.lab/current.npy')\n",
    "np_array_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since the requirement changed, the functions below are not useful anymore "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the unfolded dataframe to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder already exist\n"
     ]
    }
   ],
   "source": [
    "### a folder under /mono/csv/ called /unfolded/ will becreated which holds all datafames like above\n",
    "try:\n",
    "  # create dictionary to hold all the unfolded file \n",
    "  os.mkdir(label_path + 'csv/unfolded/');\n",
    "  print('unfolded folder created')\n",
    "except:\n",
    "  print('folder already exist')\n",
    "  pass\n",
    "for i in range(len(csvList)):\n",
    "  unfolded_df_list[i].to_csv(label_path + 'csv/unfolded/'+ csvList[i].split('/')[-1], sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After you created all the files, you can load them back to memory easily\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTICE, if you already have all the files saved, the code below is the only thing you need to load the file and start to work with your training. The code before is only for generating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## this is the path we just created\n",
    "unfolded_path = label_path + 'csv/unfolded/'\n",
    "# get all csv files \n",
    "fileNameList = [unfolded_path + f for f in os.listdir(unfolded_path) if f.endswith('.csv')]\n",
    "unfolded_df_list_ = list()\n",
    "## add all csv files as dataframe to a list\n",
    "for file in fileNameList:\n",
    "  df = pd.read_csv(file, sep='\\t')\n",
    "  unfolded_df_list_.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beg</th>\n",
       "      <th>end</th>\n",
       "      <th>before</th>\n",
       "      <th>current</th>\n",
       "      <th>next</th>\n",
       "      <th>coarse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>None</td>\n",
       "      <td>pau</td>\n",
       "      <td>n</td>\n",
       "      <td>[1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>None</td>\n",
       "      <td>pau</td>\n",
       "      <td>n</td>\n",
       "      <td>[0.9871609871609871, 0.008584008584008583, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>None</td>\n",
       "      <td>pau</td>\n",
       "      <td>n</td>\n",
       "      <td>[0.9744671403197158, 0.017095914742451153, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>None</td>\n",
       "      <td>pau</td>\n",
       "      <td>n</td>\n",
       "      <td>[0.961915688959621, 0.025537584662644806, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>233</td>\n",
       "      <td>None</td>\n",
       "      <td>pau</td>\n",
       "      <td>n</td>\n",
       "      <td>[0.949503924181845, 0.03391085443506589, 0.016...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   beg  end before current next  \\\n",
       "0    0  233   None     pau    n   \n",
       "1    0  233   None     pau    n   \n",
       "2    0  233   None     pau    n   \n",
       "3    0  233   None     pau    n   \n",
       "4    0  233   None     pau    n   \n",
       "\n",
       "                                              coarse  \n",
       "0                                          [1, 0, 0]  \n",
       "1  [0.9871609871609871, 0.008584008584008583, 0.0...  \n",
       "2  [0.9744671403197158, 0.017095914742451153, 0.0...  \n",
       "3  [0.961915688959621, 0.025537584662644806, 0.01...  \n",
       "4  [0.949503924181845, 0.03391085443506589, 0.016...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfolded_df_list_[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### of course you may also want the filename of this specify dataframe to match with raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nitech_jp_song070_f001_010.lab.csv'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the index of fileNameList maintains the same with unfolded_df_list_\n",
    "fileNameList[0].split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get one-hot-vector, call phone_to_one_hot() to a specific phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sil [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "one_hot = phone_to_one_hot('sil', phone_dict)\n",
    "print('sil', one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to access one specifiy position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pau'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### the first dataframe in the list, the index 0, and the current label\n",
    "unfolded_df_list_[0].iloc[0]['current']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
